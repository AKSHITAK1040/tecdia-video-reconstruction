{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a758533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Using device: cpu with 32 threads\n",
      "üéûÔ∏è Extracting frames from 'jumbled_video.mp4'...\n",
      "‚úÖ Extracted 300 frames\n",
      "üì• Loading frames...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:05<00:00, 58.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßÆ Computing similarity matrix with 32 threads...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44850/44850 [01:20<00:00, 556.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Similarity matrix built\n",
      "üîç Building optimal chain...\n",
      "   Start 293: Avg similarity = 0.9950\n",
      "   Start 096: Avg similarity = 0.9954\n",
      "‚úÖ Best chain: Start=096, Avg=0.9954\n",
      "\n",
      "üîß Re-optimizing last 20 frames...\n",
      "   Already optimal: 0.9928\n",
      "\n",
      "üîç Validating temporal flow (last 30 frames)...\n",
      "   ‚úÖ Flow looks good!\n",
      "\n",
      "üìã First 10: [np.int64(96), 177, 101, 203, 33, 249, 51, 102, 231, 141]\n",
      "üìã Last 10:  [276, 38, 206, 185, 73, 0, 261, 225, 283, 118]\n",
      "\n",
      "üìä End: Avg=0.9886, Min=0.9390\n",
      "\n",
      "‚úÖ No outliers\n",
      "\n",
      "üìä Final: 300/300 frames\n",
      "üé¨ Rebuilding video (300 frames)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:07<00:00, 41.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Video saved: reconstructed_video.mp4\n",
      "\n",
      "üïí Total: 99.30s\n",
      "‚úÖ Done!\n"
     ]
    }
   ],
   "source": [
    "## Run this cell to get unjumbled video. Other cells are just how i made this code step by step\n",
    "## MAIN CELL\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import multiprocessing as mp\n",
    "\n",
    "# ===============================\n",
    "# Configuration\n",
    "# ===============================\n",
    "ANALYSIS_RESIZE = (320, 180)  # Reduced resolution\n",
    "SSIM_SIZE = 7\n",
    "SSIM_SIGMA = 1.5\n",
    "SSIM_CHANNELS = 3\n",
    "SSIM_PAD = SSIM_SIZE // 2\n",
    "NUM_WORKERS = mp.cpu_count() * 2  # 2x CPU cores for I/O bound tasks\n",
    "\n",
    "# ===============================\n",
    "# Device\n",
    "# ===============================\n",
    "device = torch.device(\"cpu\")\n",
    "print(f\"‚úÖ Using device: {device} with {NUM_WORKERS} threads\")\n",
    "\n",
    "# ===============================\n",
    "# Gaussian Kernel for SSIM\n",
    "# ===============================\n",
    "def gaussian_kernel(size, sigma, channels):\n",
    "    coords = torch.arange(size).float() - size / 2 + 0.5\n",
    "    gauss = torch.exp(-(coords ** 2) / (2 * sigma ** 2))\n",
    "    gauss /= gauss.sum()\n",
    "    kernel_1d = gauss.unsqueeze(1)\n",
    "    kernel_2d = torch.matmul(kernel_1d, kernel_1d.t()).unsqueeze(0).unsqueeze(0)\n",
    "    return kernel_2d.expand(channels, 1, size, size).contiguous()\n",
    "\n",
    "SSIM_KERNEL = gaussian_kernel(SSIM_SIZE, SSIM_SIGMA, SSIM_CHANNELS)\n",
    "\n",
    "def ssim_torch(img1, img2, kernel=SSIM_KERNEL):\n",
    "    kernel = kernel.to(img1.device)\n",
    "    C1, C2 = 0.01 ** 2, 0.03 ** 2\n",
    "\n",
    "    def conv(img):\n",
    "        return F.conv2d(img, kernel, groups=SSIM_CHANNELS, padding=SSIM_PAD)\n",
    "\n",
    "    mu1, mu2 = conv(img1), conv(img2)\n",
    "    mu1_sq, mu2_sq, mu1_mu2 = mu1 ** 2, mu2 ** 2, mu1 * mu2\n",
    "    sigma1_sq = conv(img1 * img1) - mu1_sq\n",
    "    sigma2_sq = conv(img2 * img2) - mu2_sq\n",
    "    sigma12 = conv(img1 * img2) - mu1_mu2\n",
    "\n",
    "    numerator = (2 * mu1_mu2 + C1) * (2 * sigma12 + C2)\n",
    "    denominator = (mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2)\n",
    "    return (numerator / denominator).mean().item()\n",
    "\n",
    "# ===============================\n",
    "# Utilities\n",
    "# ===============================\n",
    "def to_tensor(frame, device):\n",
    "    return torch.from_numpy(frame).permute(2, 0, 1).unsqueeze(0).float().to(device) / 255.0\n",
    "\n",
    "def extract_frames(video_path, output_dir=\"frames\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    count = 0\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS) or 30)\n",
    "    print(f\"üéûÔ∏è Extracting frames from '{video_path}'...\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        cv2.imwrite(f\"{output_dir}/frame_{count:06d}.jpg\", frame)\n",
    "        count += 1\n",
    "\n",
    "    cap.release()\n",
    "    print(f\"‚úÖ Extracted {count} frames\")\n",
    "    return count, fps\n",
    "\n",
    "# ===============================\n",
    "# FIXED: Fast Similarity with ThreadPoolExecutor\n",
    "# ===============================\n",
    "def combined_similarity_fast(args):\n",
    "    \"\"\"\n",
    "    CPU-optimized similarity - no SSIM, fast operations\n",
    "    \"\"\"\n",
    "    pair_idx, frames_resized = args\n",
    "    i, j = pair_idx\n",
    "    \n",
    "    f1 = frames_resized[i]\n",
    "    f2 = frames_resized[j]\n",
    "    \n",
    "    # 1. Fast Histogram\n",
    "    h1 = cv2.calcHist([f1], [0, 1, 2], None, [6, 6, 6], [0, 256] * 3)\n",
    "    h2 = cv2.calcHist([f2], [0, 1, 2], None, [6, 6, 6], [0, 256] * 3)\n",
    "    cv2.normalize(h1, h1)\n",
    "    cv2.normalize(h2, h2)\n",
    "    hist_score = (cv2.compareHist(h1, h2, cv2.HISTCMP_CORREL) + 1) / 2\n",
    "    hist_score = np.clip(hist_score, 0, 1)\n",
    "\n",
    "    # 2. Fast Optical Flow\n",
    "    gray1 = cv2.cvtColor(f1, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(f2, cv2.COLOR_BGR2GRAY)\n",
    "    flow = cv2.calcOpticalFlowFarneback(gray1, gray2, None, 0.5, 2, 10, 2, 5, 1.1, 0)\n",
    "    flow_magnitude = np.mean(np.sqrt(flow[..., 0] ** 2 + flow[..., 1] ** 2))\n",
    "    flow_score = np.exp(-flow_magnitude / 10.0)\n",
    "    flow_score = np.clip(flow_score, 0, 1)\n",
    "\n",
    "    # 3. Fast MSE\n",
    "    f1_tiny = cv2.resize(f1, (80, 45))\n",
    "    f2_tiny = cv2.resize(f2, (80, 45))\n",
    "    mse = np.mean((f1_tiny.astype(np.float32) - f2_tiny.astype(np.float32)) ** 2)\n",
    "    mse_score = np.exp(-mse / 1000.0)\n",
    "    mse_score = np.clip(mse_score, 0, 1)\n",
    "\n",
    "    # Weighted\n",
    "    total = 0.35 * hist_score + 0.50 * flow_score + 0.15 * mse_score\n",
    "\n",
    "    return i, j, total\n",
    "\n",
    "def build_similarity_matrix_threaded(frames_resized):\n",
    "    \"\"\"\n",
    "    Fast parallel similarity using ThreadPoolExecutor (safe for OpenCV)\n",
    "    \"\"\"\n",
    "    n = len(frames_resized)\n",
    "    sim = np.zeros((n, n))\n",
    "    \n",
    "    # Create pair indices\n",
    "    pairs = [(i, j) for i in range(n) for j in range(i + 1, n)]\n",
    "    \n",
    "    print(f\"üßÆ Computing similarity matrix with {NUM_WORKERS} threads...\")\n",
    "    \n",
    "    # ThreadPoolExecutor works with OpenCV\n",
    "    with ThreadPoolExecutor(max_workers=NUM_WORKERS) as executor:\n",
    "        # Pass frames_resized as part of arguments\n",
    "        args_list = [((i, j), frames_resized) for i, j in pairs]\n",
    "        \n",
    "        results = list(\n",
    "            tqdm(\n",
    "                executor.map(combined_similarity_fast, args_list),\n",
    "                total=len(pairs),\n",
    "                ncols=100\n",
    "            )\n",
    "        )\n",
    "\n",
    "    for i, j, val in results:\n",
    "        sim[i][j] = sim[j][i] = val\n",
    "\n",
    "    print(\"‚úÖ Similarity matrix built\")\n",
    "    return sim\n",
    "\n",
    "# ===============================\n",
    "# Chain Building\n",
    "# ===============================\n",
    "def build_optimal_chain(similarity, lookahead=3):\n",
    "    n = len(similarity)\n",
    "    \n",
    "    start_scores = []\n",
    "    for i in range(n):\n",
    "        sorted_sims = np.sort(similarity[i])[::-1]\n",
    "        score = sorted_sims[0] - sorted_sims[1]\n",
    "        start_scores.append(score)\n",
    "    \n",
    "    start_candidates = np.argsort(start_scores)[-2:]\n",
    "    \n",
    "    best_chain = None\n",
    "    best_score = -999999\n",
    "    \n",
    "    print(\"üîç Building optimal chain...\")\n",
    "    \n",
    "    for start_frame in start_candidates:\n",
    "        chain = [start_frame]\n",
    "        visited = {start_frame}\n",
    "        current = start_frame\n",
    "        total_score = 0\n",
    "        \n",
    "        for step in range(n - 1):\n",
    "            unvisited = [j for j in range(n) if j not in visited]\n",
    "            if not unvisited:\n",
    "                break\n",
    "            \n",
    "            remaining_frames = len(unvisited)\n",
    "            end_game_threshold = max(20, int(0.15 * n))\n",
    "            \n",
    "            if remaining_frames <= end_game_threshold:\n",
    "                best_next = max(unvisited, key=lambda x: similarity[current][x])\n",
    "            else:\n",
    "                best_next = None\n",
    "                best_lookahead_score = -999999\n",
    "                \n",
    "                num_candidates = min(3, len(unvisited))\n",
    "                candidates = sorted(unvisited, key=lambda x: similarity[current][x], reverse=True)[:num_candidates]\n",
    "                \n",
    "                for candidate in candidates:\n",
    "                    lookahead_score = similarity[current][candidate]\n",
    "                    \n",
    "                    future_visited = visited | {candidate}\n",
    "                    future_unvisited = [j for j in range(n) if j not in future_visited]\n",
    "                    \n",
    "                    if future_unvisited:\n",
    "                        future_connections = [similarity[candidate][j] for j in future_unvisited]\n",
    "                        top_future = sorted(future_connections, reverse=True)[:min(2, len(future_connections))]\n",
    "                        lookahead_score += 0.5 * np.mean(top_future)\n",
    "                    \n",
    "                    if lookahead_score > best_lookahead_score:\n",
    "                        best_lookahead_score = lookahead_score\n",
    "                        best_next = candidate\n",
    "            \n",
    "            if best_next is None:\n",
    "                best_next = max(unvisited, key=lambda x: similarity[current][x])\n",
    "            \n",
    "            chain.append(best_next)\n",
    "            visited.add(best_next)\n",
    "            total_score += similarity[current][best_next]\n",
    "            current = best_next\n",
    "        \n",
    "        avg_score = total_score / (len(chain) - 1) if len(chain) > 1 else 0\n",
    "        \n",
    "        print(f\"   Start {start_frame:03d}: Avg similarity = {avg_score:.4f}\")\n",
    "        \n",
    "        if avg_score > best_score:\n",
    "            best_score = avg_score\n",
    "            best_chain = chain\n",
    "    \n",
    "    print(f\"‚úÖ Best chain: Start={best_chain[0]:03d}, Avg={best_score:.4f}\")\n",
    "    \n",
    "    return best_chain\n",
    "\n",
    "# ===============================\n",
    "# Post-Processing\n",
    "# ===============================\n",
    "def fix_end_sequence(order, similarity, last_n=20):\n",
    "    if len(order) <= last_n:\n",
    "        return order\n",
    "    \n",
    "    print(f\"\\nüîß Re-optimizing last {last_n} frames...\")\n",
    "    \n",
    "    fixed_part = order[:-last_n]\n",
    "    end_frames = set(order[-last_n:])\n",
    "    \n",
    "    current = fixed_part[-1]\n",
    "    new_end = []\n",
    "    \n",
    "    for _ in range(last_n):\n",
    "        if not end_frames:\n",
    "            break\n",
    "        best = max(end_frames, key=lambda x: similarity[current][x])\n",
    "        new_end.append(best)\n",
    "        end_frames.remove(best)\n",
    "        current = best\n",
    "    \n",
    "    final_order = fixed_part + new_end\n",
    "    \n",
    "    old_avg = sum(similarity[order[i]][order[i+1]] for i in range(len(order) - last_n, len(order) - 1)) / (last_n - 1)\n",
    "    new_avg = sum(similarity[final_order[i]][final_order[i+1]] for i in range(len(final_order) - last_n, len(final_order) - 1)) / (last_n - 1)\n",
    "    \n",
    "    if new_avg > old_avg:\n",
    "        print(f\"   ‚úÖ Improved: {old_avg:.4f} ‚Üí {new_avg:.4f}\")\n",
    "        return final_order\n",
    "    else:\n",
    "        print(f\"   Already optimal: {old_avg:.4f}\")\n",
    "        return order\n",
    "\n",
    "# ===============================\n",
    "# Temporal Flow Validation\n",
    "# ===============================\n",
    "def validate_and_fix_temporal_flow(order, frames_resized, similarity, validate_last_n=30):\n",
    "    if len(order) <= validate_last_n:\n",
    "        validate_last_n = len(order) - 1\n",
    "    \n",
    "    print(f\"\\nüîç Validating temporal flow (last {validate_last_n} frames)...\")\n",
    "    \n",
    "    flow_scores = []\n",
    "    bad_transitions = []\n",
    "    start_idx = len(order) - validate_last_n - 1\n",
    "    \n",
    "    for i in range(start_idx, len(order) - 1):\n",
    "        curr_frame = frames_resized[order[i]]\n",
    "        next_frame = frames_resized[order[i + 1]]\n",
    "        \n",
    "        gray1 = cv2.cvtColor(curr_frame, cv2.COLOR_BGR2GRAY)\n",
    "        gray2 = cv2.cvtColor(next_frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        flow = cv2.calcOpticalFlowFarneback(gray1, gray2, None, 0.5, 2, 10, 2, 5, 1.1, 0)\n",
    "        flow_magnitude = np.mean(np.sqrt(flow[..., 0] ** 2 + flow[..., 1] ** 2))\n",
    "        flow_scores.append(flow_magnitude)\n",
    "        \n",
    "        if len(flow_scores) >= 3:\n",
    "            recent_avg = np.mean(flow_scores[-3:])\n",
    "            if flow_magnitude > 2.0 * recent_avg and flow_magnitude > 15:\n",
    "                bad_transitions.append((i, flow_magnitude, recent_avg))\n",
    "    \n",
    "    if bad_transitions:\n",
    "        print(f\"   ‚ö†Ô∏è Found {len(bad_transitions)} issues - fixing...\")\n",
    "        return fix_problematic_section(order, frames_resized, similarity, bad_transitions)\n",
    "    else:\n",
    "        print(\"   ‚úÖ Flow looks good!\")\n",
    "        return order\n",
    "\n",
    "def fix_problematic_section(order, frames_resized, similarity, bad_transitions):\n",
    "    earliest_problem = min(pos for pos, _, _ in bad_transitions)\n",
    "    fix_start = max(0, earliest_problem - 10)\n",
    "    \n",
    "    fixed_part = order[:fix_start]\n",
    "    problem_frames = set(order[fix_start:])\n",
    "    \n",
    "    current = fixed_part[-1] if fixed_part else order[0]\n",
    "    new_section = []\n",
    "    \n",
    "    for _ in range(len(problem_frames)):\n",
    "        if not problem_frames:\n",
    "            break\n",
    "        \n",
    "        best_candidate = None\n",
    "        best_score = -1\n",
    "        \n",
    "        for candidate in problem_frames:\n",
    "            sim_score = similarity[current][candidate]\n",
    "            \n",
    "            curr_frame = frames_resized[current]\n",
    "            cand_frame = frames_resized[candidate]\n",
    "            gray1 = cv2.cvtColor(curr_frame, cv2.COLOR_BGR2GRAY)\n",
    "            gray2 = cv2.cvtColor(cand_frame, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            flow = cv2.calcOpticalFlowFarneback(gray1, gray2, None, 0.5, 2, 10, 2, 5, 1.1, 0)\n",
    "            flow_magnitude = np.mean(np.sqrt(flow[..., 0] ** 2 + flow[..., 1] ** 2))\n",
    "            flow_penalty = np.exp(-flow_magnitude / 8.0)\n",
    "            \n",
    "            combined_score = 0.7 * sim_score + 0.3 * flow_penalty\n",
    "            \n",
    "            if combined_score > best_score:\n",
    "                best_score = combined_score\n",
    "                best_candidate = candidate\n",
    "        \n",
    "        if best_candidate is not None:\n",
    "            new_section.append(best_candidate)\n",
    "            problem_frames.remove(best_candidate)\n",
    "            current = best_candidate\n",
    "    \n",
    "    return fixed_part + new_section\n",
    "\n",
    "# ===============================\n",
    "# Outlier Removal\n",
    "# ===============================\n",
    "def remove_outliers(order, similarity, threshold=0.10):\n",
    "    n = len(order)\n",
    "    clean_order = [order[0]]\n",
    "    removed_count = 0\n",
    "    \n",
    "    for i in range(1, n):\n",
    "        prev_idx = order[i - 1]\n",
    "        curr_idx = order[i]\n",
    "        sim_score = similarity[prev_idx][curr_idx]\n",
    "        \n",
    "        position_ratio = i / n\n",
    "        adjusted_threshold = threshold * 0.6 if position_ratio > 0.8 else threshold\n",
    "        \n",
    "        if sim_score > adjusted_threshold:\n",
    "            clean_order.append(curr_idx)\n",
    "        else:\n",
    "            removed_count += 1\n",
    "    \n",
    "    if removed_count > 0:\n",
    "        print(f\"\\n‚ö†Ô∏è Removed {removed_count} outliers\")\n",
    "    else:\n",
    "        print(\"\\n‚úÖ No outliers\")\n",
    "    \n",
    "    return clean_order\n",
    "\n",
    "# ===============================\n",
    "# Rebuild Video\n",
    "# ===============================\n",
    "def rebuild_video(order, frame_dir=\"frames\", output_file=\"reconstructed_video.mp4\", fps=30):\n",
    "    sample = cv2.imread(f\"{frame_dir}/frame_000000.jpg\")\n",
    "    h, w, _ = sample.shape\n",
    "    out = cv2.VideoWriter(output_file, cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
    "\n",
    "    print(f\"üé¨ Rebuilding video ({len(order)} frames)...\")\n",
    "\n",
    "    def load_frame(idx):\n",
    "        return cv2.imread(f\"{frame_dir}/frame_{idx:06d}.jpg\")\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=NUM_WORKERS) as executor:\n",
    "        for frame in tqdm(executor.map(load_frame, order), total=len(order), desc=\"Writing\", ncols=100):\n",
    "            if frame is not None:\n",
    "                out.write(frame)\n",
    "\n",
    "    out.release()\n",
    "    print(f\"‚úÖ Video saved: {output_file}\")\n",
    "\n",
    "# ===============================\n",
    "# Main\n",
    "# ===============================\n",
    "def main(video_path):\n",
    "    start_time = time.time()\n",
    "\n",
    "    total, fps = extract_frames(video_path)\n",
    "\n",
    "    print(\"üì• Loading frames...\")\n",
    "    frames_resized = []\n",
    "    for i in tqdm(range(total), desc=\"Loading\", ncols=100):\n",
    "        frame = cv2.imread(f\"frames/frame_{i:06d}.jpg\")\n",
    "        frame_resized = cv2.resize(frame, ANALYSIS_RESIZE)\n",
    "        frames_resized.append(frame_resized)\n",
    "\n",
    "    similarity = build_similarity_matrix_threaded(frames_resized)\n",
    "    best_order = build_optimal_chain(similarity)\n",
    "    best_order = fix_end_sequence(best_order, similarity, last_n=20)\n",
    "    best_order = validate_and_fix_temporal_flow(best_order, frames_resized, similarity, validate_last_n=30)\n",
    "    \n",
    "    print(f\"\\nüìã First 10: {best_order[:10]}\")\n",
    "    print(f\"üìã Last 10:  {best_order[-10:]}\")\n",
    "    \n",
    "    if len(best_order) >= 11:\n",
    "        end_sims = [similarity[best_order[i]][best_order[i + 1]] for i in range(len(best_order) - 11, len(best_order) - 1)]\n",
    "        print(f\"\\nüìä End: Avg={np.mean(end_sims):.4f}, Min={np.min(end_sims):.4f}\")\n",
    "    \n",
    "    clean_order = remove_outliers(best_order, similarity, threshold=0.10)\n",
    "    print(f\"\\nüìä Final: {len(clean_order)}/{total} frames\")\n",
    "\n",
    "    rebuild_video(clean_order, fps=fps)\n",
    "\n",
    "    print(f\"\\nüïí Total: {time.time() - start_time:.2f}s\")\n",
    "    print(\"‚úÖ Done!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(\"jumbled_video.mp4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c547fab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Using device: cpu with 32 threads\n"
     ]
    }
   ],
   "source": [
    "# DAY1:Setting up basic frame extraction\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import multiprocessing as mp\n",
    "\n",
    "# ===============================\n",
    "# Configuration\n",
    "# ===============================\n",
    "ANALYSIS_RESIZE = (320, 180)\n",
    "SSIM_SIZE = 7\n",
    "SSIM_SIGMA = 1.5\n",
    "SSIM_CHANNELS = 3\n",
    "SSIM_PAD = SSIM_SIZE // 2\n",
    "NUM_WORKERS = mp.cpu_count() * 2  # 2x CPU cores for I/O bound tasks\n",
    "\n",
    "# ===============================\n",
    "# Device\n",
    "# ===============================\n",
    "device = torch.device(\"cpu\")\n",
    "print(f\"‚úÖ Using device: {device} with {NUM_WORKERS} threads\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71bce88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================\n",
    "# DAY 2: GPU Detection + SSIM Kernel\n",
    "# =====================================\n",
    "def gaussian_kernel(size, sigma, channels):\n",
    "    coords = torch.arange(size).float() - size / 2 + 0.5\n",
    "    gauss = torch.exp(-(coords ** 2) / (2 * sigma ** 2))\n",
    "    gauss /= gauss.sum()\n",
    "    kernel_1d = gauss.unsqueeze(1)\n",
    "    kernel_2d = torch.matmul(kernel_1d, kernel_1d.t()).unsqueeze(0).unsqueeze(0)\n",
    "    return kernel_2d.expand(channels, 1, size, size).contiguous()\n",
    "\n",
    "SSIM_KERNEL = gaussian_kernel(SSIM_SIZE, SSIM_SIGMA, SSIM_CHANNELS)\n",
    "\n",
    "def ssim_torch(img1, img2, kernel=SSIM_KERNEL):\n",
    "    kernel = kernel.to(img1.device)\n",
    "    C1, C2 = 0.01 ** 2, 0.03 ** 2\n",
    "\n",
    "    def conv(img):\n",
    "        return F.conv2d(img, kernel, groups=SSIM_CHANNELS, padding=SSIM_PAD)\n",
    "\n",
    "    mu1, mu2 = conv(img1), conv(img2)\n",
    "    mu1_sq, mu2_sq, mu1_mu2 = mu1 ** 2, mu2 ** 2, mu1 * mu2\n",
    "    sigma1_sq = conv(img1 * img1) - mu1_sq\n",
    "    sigma2_sq = conv(img2 * img2) - mu2_sq\n",
    "    sigma12 = conv(img1 * img2) - mu1_mu2\n",
    "\n",
    "    numerator = (2 * mu1_mu2 + C1) * (2 * sigma12 + C2)\n",
    "    denominator = (mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2)\n",
    "    return (numerator / denominator).mean().item()\n",
    "\n",
    "# Convert frame to tensor\n",
    "def to_tensor(frame, device):\n",
    "    return torch.from_numpy(frame).permute(2, 0, 1).unsqueeze(0).float().to(device) / 255.0\n",
    "\n",
    "# Extract frames\n",
    "def extract_frames(video_path, output_dir=\"frames\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    count = 0\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS) or 30)\n",
    "    print(f\"üéûÔ∏è Extracting frames from '{video_path}'...\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        cv2.imwrite(f\"{output_dir}/frame_{count:06d}.jpg\", frame)\n",
    "        count += 1\n",
    "\n",
    "    cap.release()\n",
    "    print(f\"‚úÖ Extracted {count} frames\")\n",
    "    return count, fps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db543a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# üß© Day 3: Frame Similarity Matrix (Histogram + Flow + SSIM)\n",
    "# ===============================\n",
    "\n",
    "def combined_similarity_fast(args):\n",
    "    pair_idx, frames_resized = args\n",
    "    i, j = pair_idx\n",
    "    \n",
    "    f1, f2 = frames_resized[i], frames_resized[j]\n",
    "\n",
    "    # 1. Histogram similarity\n",
    "    h1 = cv2.calcHist([f1], [0,1,2], None, [6,6,6], [0,256]*3)\n",
    "    h2 = cv2.calcHist([f2], [0,1,2], None, [6,6,6], [0,256]*3)\n",
    "    cv2.normalize(h1, h1); cv2.normalize(h2, h2)\n",
    "    hist_score = (cv2.compareHist(h1, h2, cv2.HISTCMP_CORREL) + 1) / 2\n",
    "    hist_score = np.clip(hist_score, 0, 1)\n",
    "\n",
    "    # 2. Optical flow\n",
    "    g1, g2 = cv2.cvtColor(f1, cv2.COLOR_BGR2GRAY), cv2.cvtColor(f2, cv2.COLOR_BGR2GRAY)\n",
    "    flow = cv2.calcOpticalFlowFarneback(g1, g2, None, 0.5, 2, 10, 2, 5, 1.1, 0)\n",
    "    flow_mag = np.mean(np.sqrt(flow[...,0]**2 + flow[...,1]**2))\n",
    "    flow_score = np.clip(np.exp(-flow_mag / 10.0), 0, 1)\n",
    "\n",
    "    # 3. Fast MSE\n",
    "    f1_tiny = cv2.resize(f1, (80,45))\n",
    "    f2_tiny = cv2.resize(f2, (80,45))\n",
    "    mse = np.mean((f1_tiny.astype(np.float32) - f2_tiny.astype(np.float32))**2)\n",
    "    mse_score = np.clip(np.exp(-mse / 1000.0), 0, 1)\n",
    "\n",
    "    # Weighted sum\n",
    "    total = 0.35*hist_score + 0.50*flow_score + 0.15*mse_score\n",
    "    return i, j, total\n",
    "\n",
    "def build_similarity_matrix_threaded(frames_resized):\n",
    "    n = len(frames_resized)\n",
    "    sim = np.zeros((n, n))\n",
    "    pairs = [(i, j) for i in range(n) for j in range(i + 1, n)]\n",
    "    \n",
    "    print(f\"üßÆ Computing similarity matrix with {NUM_WORKERS} threads...\")\n",
    "    with ThreadPoolExecutor(max_workers=NUM_WORKERS) as executor:\n",
    "        args_list = [((i, j), frames_resized) for i, j in pairs]\n",
    "        results = list(tqdm(executor.map(combined_similarity_fast, args_list),\n",
    "                            total=len(pairs), ncols=100))\n",
    "    for i, j, val in results:\n",
    "        sim[i][j] = sim[j][i] = val\n",
    "    print(\"‚úÖ Similarity matrix built\")\n",
    "    return sim\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5d99f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Day 4 ‚Äî Optimal Chain Building & Refinements\n",
    "\n",
    "def build_optimal_chain(similarity, lookahead=3):\n",
    "    n = len(similarity)\n",
    "    start_scores = []\n",
    "    for i in range(n):\n",
    "        sorted_sims = np.sort(similarity[i])[::-1]\n",
    "        score = sorted_sims[0] - sorted_sims[1]\n",
    "        start_scores.append(score)\n",
    "    start_candidates = np.argsort(start_scores)[-2:]\n",
    "\n",
    "    best_chain, best_score = None, -999999\n",
    "    print(\"üîç Building optimal chain...\")\n",
    "\n",
    "    for start_frame in start_candidates:\n",
    "        chain = [start_frame]; visited = {start_frame}\n",
    "        current, total_score = start_frame, 0\n",
    "\n",
    "        for step in range(n - 1):\n",
    "            unvisited = [j for j in range(n) if j not in visited]\n",
    "            if not unvisited: break\n",
    "\n",
    "            remaining_frames = len(unvisited)\n",
    "            end_game_threshold = max(20, int(0.15 * n))\n",
    "\n",
    "            if remaining_frames <= end_game_threshold:\n",
    "                best_next = max(unvisited, key=lambda x: similarity[current][x])\n",
    "            else:\n",
    "                best_next = None; best_lookahead_score = -999999\n",
    "                candidates = sorted(unvisited, key=lambda x: similarity[current][x], reverse=True)[:3]\n",
    "                for candidate in candidates:\n",
    "                    lookahead_score = similarity[current][candidate]\n",
    "                    future_unvisited = [j for j in unvisited if j != candidate]\n",
    "                    if future_unvisited:\n",
    "                        future_conn = [similarity[candidate][j] for j in future_unvisited]\n",
    "                        top_future = sorted(future_conn, reverse=True)[:2]\n",
    "                        lookahead_score += 0.5 * np.mean(top_future)\n",
    "                    if lookahead_score > best_lookahead_score:\n",
    "                        best_lookahead_score, best_next = lookahead_score, candidate\n",
    "\n",
    "            chain.append(best_next)\n",
    "            visited.add(best_next)\n",
    "            total_score += similarity[current][best_next]\n",
    "            current = best_next\n",
    "\n",
    "        avg_score = total_score / (len(chain) - 1)\n",
    "        print(f\"   Start {start_frame:03d}: Avg similarity = {avg_score:.4f}\")\n",
    "        if avg_score > best_score:\n",
    "            best_score, best_chain = avg_score, chain\n",
    "\n",
    "    print(f\"‚úÖ Best chain: Start={best_chain[0]:03d}, Avg={best_score:.4f}\")\n",
    "    return best_chain\n",
    "\n",
    "\n",
    "# Post-processing utilities (fix end, validate flow, remove outliers)\n",
    "def fix_end_sequence(order, similarity, last_n=20):\n",
    "    if len(order) <= last_n: return order\n",
    "    print(f\"\\nüîß Re-optimizing last {last_n} frames...\")\n",
    "    fixed_part = order[:-last_n]\n",
    "    end_frames = set(order[-last_n:])\n",
    "    current = fixed_part[-1]; new_end = []\n",
    "    for _ in range(last_n):\n",
    "        if not end_frames: break\n",
    "        best = max(end_frames, key=lambda x: similarity[current][x])\n",
    "        new_end.append(best)\n",
    "        end_frames.remove(best)\n",
    "        current = best\n",
    "    final_order = fixed_part + new_end\n",
    "    return final_order\n",
    "\n",
    "\n",
    "def remove_outliers(order, similarity, threshold=0.10):\n",
    "    n = len(order); clean_order = [order[0]]; removed = 0\n",
    "    for i in range(1, n):\n",
    "        prev_idx, curr_idx = order[i-1], order[i]\n",
    "        sim_score = similarity[prev_idx][curr_idx]\n",
    "        if sim_score > threshold:\n",
    "            clean_order.append(curr_idx)\n",
    "        else:\n",
    "            removed += 1\n",
    "    print(f\"\\n‚ö†Ô∏è Removed {removed} outliers\" if removed else \"\\n‚úÖ No outliers\")\n",
    "    return clean_order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbd3eb73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéûÔ∏è Extracting frames from 'jumbled_video.mp4'...\n",
      "‚úÖ Extracted 300 frames\n",
      "üì• Loading frames...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:05<00:00, 58.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßÆ Computing similarity matrix with 32 threads...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44850/44850 [01:16<00:00, 589.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Similarity matrix built\n",
      "üîç Building optimal chain...\n",
      "   Start 293: Avg similarity = 0.9950\n",
      "   Start 096: Avg similarity = 0.9954\n",
      "‚úÖ Best chain: Start=096, Avg=0.9954\n",
      "\n",
      "üîß Re-optimizing last 20 frames...\n",
      "\n",
      "‚úÖ No outliers\n",
      "üé¨ Rebuilding video (300 frames)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:08<00:00, 36.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Video saved: reconstructed_video.mp4\n",
      "\n",
      "üïí Total time: 97.11s\n",
      "‚úÖ Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Day 5 ‚Äî Rebuilding Video & Main Pipeline\n",
    "\n",
    "def rebuild_video(order, frame_dir=\"frames\", output_file=\"reconstructed_video.mp4\", fps=30):\n",
    "    sample = cv2.imread(f\"{frame_dir}/frame_000000.jpg\")\n",
    "    h, w, _ = sample.shape\n",
    "    out = cv2.VideoWriter(output_file, cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
    "    print(f\"üé¨ Rebuilding video ({len(order)} frames)...\")\n",
    "\n",
    "    def load_frame(idx):\n",
    "        return cv2.imread(f\"{frame_dir}/frame_{idx:06d}.jpg\")\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=NUM_WORKERS) as executor:\n",
    "        for frame in tqdm(executor.map(load_frame, order), total=len(order), desc=\"Writing\", ncols=100):\n",
    "            if frame is not None:\n",
    "                out.write(frame)\n",
    "\n",
    "    out.release()\n",
    "    print(f\"‚úÖ Video saved: {output_file}\")\n",
    "\n",
    "\n",
    "def main(video_path):\n",
    "    start_time = time.time()\n",
    "    total, fps = extract_frames(video_path)\n",
    "\n",
    "    print(\"üì• Loading frames...\")\n",
    "    frames_resized = []\n",
    "    for i in tqdm(range(total), desc=\"Loading\", ncols=100):\n",
    "        frame = cv2.imread(f\"frames/frame_{i:06d}.jpg\")\n",
    "        frame_resized = cv2.resize(frame, ANALYSIS_RESIZE)\n",
    "        frames_resized.append(frame_resized)\n",
    "\n",
    "    similarity = build_similarity_matrix_threaded(frames_resized)\n",
    "    best_order = build_optimal_chain(similarity)\n",
    "    best_order = fix_end_sequence(best_order, similarity, last_n=20)\n",
    "    clean_order = remove_outliers(best_order, similarity, threshold=0.10)\n",
    "    rebuild_video(clean_order, fps=fps)\n",
    "\n",
    "    print(f\"\\nüïí Total time: {time.time() - start_time:.2f}s\")\n",
    "    print(\"‚úÖ Done!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(\"jumbled_video.mp4\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
